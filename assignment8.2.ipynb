{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to treat this as a classification problem by creating a new binary variable affair\n",
    "(did the woman have at least one affair?) and trying to predict the classification for each\n",
    "woman.\n",
    "Dataset\n",
    "The dataset I chose is the affairs dataset that comes with Statsmodels. It was derived\n",
    "from a survey of women in 1974 by Redbook magazine, in which married women were\n",
    "asked about their participation in extramarital affairs. More information about the study\n",
    "is available in a 1978 paper from the Journal of Political Economy.\n",
    "Description of Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 6366 observations of 9 variables:\n",
    "rate_marriage: woman's rating of her marriage (1 = very poor, 5 = very good)\n",
    "age: woman's age\n",
    "yrs_married: number of years married\n",
    "children: number of children\n",
    "religious: woman's rating of how religious she is (1 = not religious, 4 = strongly religious)\n",
    "educ: level of education (9 = grade school, 12 = high school, 14 = some college, 16 =\n",
    "college graduate, 17 = some graduate school, 20 = advanced degree)\n",
    "occupation: woman's occupation (1 = student, 2 = farming/semi-skilled/unskilled, 3 =\n",
    "\"white collar\", 4 = teacher/nurse/writer/technician/skilled, 5 = managerial/business, 6 =\n",
    "professional with advanced degree)\n",
    "occupation_husb: husband's occupation (same coding as above)\n",
    "affairs: time spent in extra-marital affairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a stacked barplot to look at the percentage of women having affairs by number of years of marriage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Intercept', 'C(occupation)[T.2.0]', 'C(occupation)[T.3.0]',\n",
       "       'C(occupation)[T.4.0]', 'C(occupation)[T.5.0]', 'C(occupation)[T.6.0]',\n",
       "       'C(occupation_husb)[T.2.0]', 'C(occupation_husb)[T.3.0]',\n",
       "       'C(occupation_husb)[T.4.0]', 'C(occupation_husb)[T.5.0]',\n",
       "       'C(occupation_husb)[T.6.0]', 'rate_marriage', 'age', 'yrs_married',\n",
       "       'children', 'religious', 'educ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframes with an intercept column and dummy variables for\n",
    "# occupation and occupation_husb\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + \\\n",
    "                  religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names for the dummy variables are ugly, so let's rename those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column names of X\n",
    "X = X.rename(columns = {'C(occupation)[T.2.0]':'occ_2',\n",
    "                        'C(occupation)[T.3.0]':'occ_3',\n",
    "                        'C(occupation)[T.4.0]':'occ_4',\n",
    "                        'C(occupation)[T.5.0]':'occ_5',\n",
    "                        'C(occupation)[T.6.0]':'occ_6',\n",
    "                        'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "                        'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "                        'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "                        'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "                        'C(occupation_husb)[T.6.0]':'occ_husb_6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258875274897895"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3224945020420987"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what percentage had affairs?\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to predict class labels for the test set. We will also generate the class probabilities, just to take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# predict class labels for the test set\n",
    "predicted = model2.predict(X_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3514634  0.6485366 ]\n",
      " [0.90955084 0.09044916]\n",
      " [0.72567333 0.27432667]\n",
      " ...\n",
      " [0.55727385 0.44272615]\n",
      " [0.81207043 0.18792957]\n",
      " [0.74734601 0.25265399]]\n"
     ]
    }
   ],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the classifier is predicting a 1 (having an affair) any time the probability in the second column is greater than 0.5.\n",
    "\n",
    "Now let's generate some evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298429319371728\n",
      "0.745950606950631\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 73%, which is the same as we experienced when training and predicting on the same data.\n",
    "\n",
    "We can also see the confusion matrix and a classification report with other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1169  134]\n",
      " [ 382  225]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.90      0.82      1303\n",
      "        1.0       0.63      0.37      0.47       607\n",
      "\n",
      "avg / total       0.71      0.73      0.71      1910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
